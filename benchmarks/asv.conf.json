{
    // The version of the config file format.  Do not change, unless
    // you know what you are doing.
    "version": 1,

    // The name of the project being benchmarked
    "project": "zarrtraj",

    // The project's homepage
    "project_url": "https://zarrtraj.readthedocs.io/en/latest/index.html",

    // The URL or local path of the source code repository for the
    // project being benchmarked
    "repo": "..",

    // List of branches to benchmark. 
    "branches": ["develop"],

    // The DVCS being used.  
    "dvcs": "git",

    // The tool to use to create environments. 
    "environment_type": "conda",

    // the base URL to show a commit for the project.
    "show_commit_url": "https://github.com/Becksteinlab/zarrtraj/commit",

    // The Pythons you'd like to test against.  If not provided, defaults
    // to the current version of Python used to run `asv`.
    "pythons": ["3.10"],

    // The list of conda channel names to be searched for benchmark
    // dependency packages in the specified order
    "conda_channels": ["conda-forge", "defaults"],

    // A conda environment file that is used for environment creation.
    // "conda_environment_file": "environment.yml",

    // The matrix of dependencies to test.  Each key of the "req"
    // requirements dictionary is the name of a package (in PyPI) and
    // the values are version numbers.  An empty list or empty string
    // indicates to just test against the default (latest)
    // version. null indicates that the package is to not be
    // installed. If the package to be tested is only available from
    // PyPi, and the 'environment_type' is conda, then you can preface
    // the package name by 'pip+', and the package will be installed
    // via pip (with all the conda available packages installed first,
    // followed by the pip installed packages).
    //
    // The ``@env`` and ``@env_nobuild`` keys contain the matrix of
    // environment variables to pass to build and benchmark commands.
    // An environment will be created for every combination of the
    // cartesian product of the "@env" variables in this matrix.
    // Variables in "@env_nobuild" will be passed to every environment
    // during the benchmark phase, but will not trigger creation of
    // new environments.  A value of ``null`` means that the variable
    // will not be set for the current combination.
    //
    // "matrix": {
    //     "req": {
    //         "numpy": ["1.6", "1.7"],
    //         "six": ["", null],  // test with and without six installed
    //         "pip+emcee": [""]   // emcee is only available for install with pip.
    //     },
    //     "env": {"ENV_VAR_1": ["val1", "val2"]},
    //     "env_nobuild": {"ENV_VAR_2": ["val3", null]},
    // },

    // The directory (relative to the current directory) that benchmarks are
    // stored in.  If not provided, defaults to "benchmarks"
    "benchmark_dir": ".",

    // The directory (relative to the current directory) to cache the Python
    // environments in.  If not provided, defaults to "env"
    "env_dir": ".asv/env",

    // The directory (relative to the current directory) that raw benchmark
    // results are stored in.  If not provided, defaults to "results".
    "results_dir": ".asv/results",

    // The directory (relative to the current directory) that the html tree
    // should be written to.  If not provided, defaults to "html".
    "html_dir": ".asv/html",

    // The number of characters to retain in the commit hashes.
    // "hash_length": 8,

    // `asv` will cache results of the recent builds in each
    // environment, making them faster to install next time.  This is
    // the number of builds to keep, per environment.
    "build_cache_size": 2,

    // Build instructions
    "build_command": [
        "python -m pip install build",
        "python -m build --wheel -o {build_cache_dir} {build_dir}",
    ],
}
